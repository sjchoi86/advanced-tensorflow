{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE CHAR-RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSORFLOW VERSION IS 1.0.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "tf.set_random_seed(0)  \n",
    "print (\"TENSORFLOW VERSION IS %s\" % (tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE TRAINING SEQUENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLLOWING IS OUR TRAINING SEQUENCE:\n",
      "Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\n"
     ]
    }
   ],
   "source": [
    "quote1 = (\"If you want to build a ship, \"\n",
    "          \"don't drum up people to collect wood and don't assign them tasks and work,\"\n",
    "          \" but rather teach them to long for the endless immensity of the sea.\")\n",
    "quote2 = (\"Perfection is achieved, \"\n",
    "          \"not when there is nothing more to add, \"\n",
    "          \"but when there is nothing left to take away.\")\n",
    "sentence = quote2\n",
    "print (\"FOLLOWING IS OUR TRAINING SEQUENCE:\")\n",
    "print (sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE VOCABULARY AND DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY: \n",
      "[' ', ',', '.', 'P', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'm', 'l', 'o', 'n', 's', 'r', 'u', 't', 'w', 'v', 'y']\n",
      "DICTIONARY: \n",
      "{' ': 0, ',': 1, '.': 2, 'P': 3, 'a': 4, 'c': 5, 'b': 6, 'e': 7, 'd': 8, 'g': 9, 'f': 10, 'i': 11, 'h': 12, 'k': 13, 'm': 14, 'l': 15, 'o': 16, 'n': 17, 's': 18, 'r': 19, 'u': 20, 't': 21, 'w': 22, 'v': 23, 'y': 24}\n"
     ]
    }
   ],
   "source": [
    "char_set = list(set(sentence))\n",
    "char_dic = {w: i for i, w in enumerate(char_set)}\n",
    "print (\"VOCABULARY: \")\n",
    "print (char_set)\n",
    "print (\"DICTIONARY: \")\n",
    "print (char_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim    = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "hidden_size     = 64\n",
    "sequence_length = 10  # Any arbitrary number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET TRAINING BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0/ 107] [Perfection]=>[erfection ]\n",
      "            [3, 7, 19, 10, 7, 5, 21, 11, 16, 17]=>[7, 19, 10, 7, 5, 21, 11, 16, 17, 0]\n",
      "[   1/ 107] [erfection ]=>[rfection i]\n",
      "            [7, 19, 10, 7, 5, 21, 11, 16, 17, 0]=>[19, 10, 7, 5, 21, 11, 16, 17, 0, 11]\n",
      "[   2/ 107] [rfection i]=>[fection is]\n",
      "            [19, 10, 7, 5, 21, 11, 16, 17, 0, 11]=>[10, 7, 5, 21, 11, 16, 17, 0, 11, 18]\n",
      "[   3/ 107] [fection is]=>[ection is ]\n",
      "            [10, 7, 5, 21, 11, 16, 17, 0, 11, 18]=>[7, 5, 21, 11, 16, 17, 0, 11, 18, 0]\n",
      "[   4/ 107] [ection is ]=>[ction is a]\n",
      "            [7, 5, 21, 11, 16, 17, 0, 11, 18, 0]=>[5, 21, 11, 16, 17, 0, 11, 18, 0, 4]\n",
      "[   5/ 107] [ction is a]=>[tion is ac]\n",
      "            [5, 21, 11, 16, 17, 0, 11, 18, 0, 4]=>[21, 11, 16, 17, 0, 11, 18, 0, 4, 5]\n",
      "[   6/ 107] [tion is ac]=>[ion is ach]\n",
      "            [21, 11, 16, 17, 0, 11, 18, 0, 4, 5]=>[11, 16, 17, 0, 11, 18, 0, 4, 5, 12]\n",
      "[   7/ 107] [ion is ach]=>[on is achi]\n",
      "            [11, 16, 17, 0, 11, 18, 0, 4, 5, 12]=>[16, 17, 0, 11, 18, 0, 4, 5, 12, 11]\n",
      "[   8/ 107] [on is achi]=>[n is achie]\n",
      "            [16, 17, 0, 11, 18, 0, 4, 5, 12, 11]=>[17, 0, 11, 18, 0, 4, 5, 12, 11, 7]\n",
      "[   9/ 107] [n is achie]=>[ is achiev]\n",
      "            [17, 0, 11, 18, 0, 4, 5, 12, 11, 7]=>[0, 11, 18, 0, 4, 5, 12, 11, 7, 23]\n"
     ]
    }
   ],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i + sequence_length]\n",
    "    y_str = sentence[i + 1: i + sequence_length + 1]\n",
    "    x = [char_dic[c] for c in x_str]  # x str to index\n",
    "    y = [char_dic[c] for c in y_str]  # y str to index\n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "    if i < 10:\n",
    "        print (\"[%4d/%4d] [%s]=>[%s]\" % (i, len(sentence), x_str, y_str))\n",
    "        print (\"%s%s=>%s\" % (' '*12, x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     'NDATA' IS 97\n",
      "'BATCH_SIZE' IS 512\n"
     ]
    }
   ],
   "source": [
    "ndata      = len(dataX)\n",
    "batch_size = 512\n",
    "print (\"     'NDATA' IS %d\" % (ndata))\n",
    "print (\"'BATCH_SIZE' IS %d\" % (batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE PLACEHOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sequence_length' IS [10]\n",
      "    'num_classes' IS [25]\n",
      "'X' LOOKS LIKE \n",
      "   [Tensor(\"Placeholder:0\", shape=(?, 10), dtype=int32)]\n",
      "'X_OH' LOOKS LIKE \n",
      "   [Tensor(\"one_hot:0\", shape=(?, 10, 25), dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "X_OH = tf.one_hot(X, num_classes)\n",
    "print (\"'sequence_length' IS [%d]\" % (sequence_length))\n",
    "print (\"    'num_classes' IS [%d]\" % (num_classes))\n",
    "print(\"'X' LOOKS LIKE \\n   [%s]\" % (X))  \n",
    "print(\"'X_OH' LOOKS LIKE \\n   [%s]\" % (X_OH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUTS LOOKS LIKE [Tensor(\"CHAR-RNN/Reshape:0\", shape=(512, 10, 25), dtype=float32)]\n",
      "MODEL DEFINED.\n"
     ]
    }
   ],
   "source": [
    "num_hidden = 128\n",
    "with tf.variable_scope('CHAR-RNN', reuse=False):\n",
    "    cell = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "    cell = rnn.MultiRNNCell([cell] * 2, state_is_tuple=True)\n",
    "    # DYNAMIC RNN WITH FULLY CONNECTED LAYER\n",
    "    _hiddens  = tf.contrib.layers.fully_connected(X_OH, num_hidden, activation_fn=tf.nn.relu)\n",
    "    _outputs, _states = tf.nn.dynamic_rnn(cell, _hiddens, dtype=tf.float32)\n",
    "    _outputs  = tf.contrib.layers.fully_connected(_outputs, num_classes, activation_fn=None)\n",
    "    # RESHAPE FOR SEQUNCE LOSS\n",
    "    outputs = tf.reshape(_outputs, [batch_size, sequence_length, num_classes])\n",
    "print (\"OUTPUTS LOOKS LIKE [%s]\" % (outputs))\n",
    "print (\"MODEL DEFINED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE TF FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNCTIONS DEFINED.\n"
     ]
    }
   ],
   "source": [
    "weights = tf.ones([batch_size, sequence_length]) # EQUAL WEIGHTS\n",
    "seq_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "    logits=outputs, targets=Y, weights=weights)\n",
    "loss  = tf.reduce_mean(seq_loss)\n",
    "optm  = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)\n",
    "print (\"FUNCTIONS DEFINED.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTIMIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0] loss_val: 3.21864 \n",
      "[  200] loss_val: 0.60841 \n",
      "[  400] loss_val: 0.21809 \n",
      "[  600] loss_val: 0.18507 \n",
      "[  800] loss_val: 0.17569 \n",
      "[ 1000] loss_val: 0.17517 \n",
      "[ 1200] loss_val: 0.18346 \n",
      "[ 1400] loss_val: 0.17449 \n",
      "[ 1600] loss_val: 0.17073 \n",
      "[ 1800] loss_val: 0.16770 \n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "MAXITER = 2000\n",
    "for i in range(MAXITER):\n",
    "    randidx = np.random.randint(low=0, high=ndata, size=batch_size)\n",
    "    batchX = [dataX[iii] for iii in randidx]\n",
    "    batchY = [dataY[iii] for iii in randidx]\n",
    "    feeds = {X: batchX, Y: batchY}\n",
    "    _, loss_val, results = sess.run(\n",
    "        [optm, loss, outputs], feed_dict=feeds)\n",
    "    if (i%200) == 0:\n",
    "        print (\"[%5d] loss_val: %.5f \" % (i, loss_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRINT CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 'n', 'g', ' ', 'm', 'e', 'f']\n",
      "['e', ' ', 'i', 's', ' ', 'n', 'o', 't', 'h', 'i']\n",
      "['e', 'e', 'c', 't', 'i', 'o', 'n', ' ', 'i', 's']\n",
      "[' ', ',', ' ', 'n', 'o', 't', ' ', 'w', 'h', 'e']\n",
      "['h', ' ', 'a', 'd', 'd', ',', ' ', 'b', 'u', 't']\n",
      "[' ', ' ', 't', 'h', 'e', 'r', 'e', ' ', 'i', 's']\n",
      "['s', 'g', ' ', 'm', 'e', 'f', 't', ' ', 't', 'o']\n",
      "['t', 's', ' ', 'n', 'o', 't', 'h', 'i', 'n', 'g']\n",
      "['h', 'i', 'r', 'e', ' ', 'i', 's', ' ', 'n', 'o']\n",
      "['t', 'o', 'r', 'e', ' ', 't', 'o', ' ', 'a', 'd']\n"
     ]
    }
   ],
   "source": [
    "randidx = np.random.randint(low=0, high=ndata, size=batch_size)\n",
    "batchX = [dataX[iii] for iii in randidx]\n",
    "batchY = [dataY[iii] for iii in randidx]\n",
    "feeds = {X: batchX, Y: batchY}\n",
    "results = sess.run(outputs, feed_dict=feeds)\n",
    "for j, result in enumerate(results):\n",
    "    index = np.argmax(result, axis=1)\n",
    "    chars = [char_set[t] for t in index]\n",
    "    if j < 10:\n",
    "        print (chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLING FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_2:0\", shape=(?, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "LEN = 1;\n",
    "# XL = tf.placeholder(tf.int32, [None, LEN])\n",
    "XL     = tf.placeholder(tf.int32, [None, 1])\n",
    "XL_OH  = tf.one_hot(XL, num_classes)\n",
    "with tf.variable_scope('CHAR-RNN', reuse=True):\n",
    "    cell_L = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "    cell_L = rnn.MultiRNNCell([cell_L] * 2, state_is_tuple=True)\n",
    "    istate = cell_L.zero_state(batch_size=1, dtype=tf.float32)\n",
    "    # DYNAMIC RNN WITH FULLY CONNECTED LAYER\n",
    "    _hiddens  = tf.contrib.layers.fully_connected(XL_OH, num_hidden, activation_fn=tf.nn.tanh)\n",
    "    _outputs_L, states_L = tf.nn.dynamic_rnn(cell_L, _hiddens\n",
    "                                , initial_state=istate, dtype=tf.float32)\n",
    "    _outputs_L  = tf.contrib.layers.fully_connected(\n",
    "        _outputs_L, num_classes, activation_fn=None)\n",
    "    # RESHAPE FOR SEQUNCE LOSS\n",
    "    outputs_L = tf.reshape(_outputs_L, [LEN, 1, num_classes])\n",
    "print (XL)\n",
    "\n",
    "def weighted_pick(weights):\n",
    "    t = np.cumsum(weights)\n",
    "    s = np.sum(weights)\n",
    "    return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "def softmax(x):\n",
    "    alpha = 1\n",
    "    e_x = np.exp(alpha*(x - np.max(x)))\n",
    "    return e_x / np.sum(e_x) # only difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BURNIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prime = \"Perfection is\"\n",
    "istateval = sess.run(cell_L.zero_state(1, tf.float32))\n",
    "for c in prime[:-1]:\n",
    "    index = char_dic[c]\n",
    "    inval = [[index]]\n",
    "    outval, stateval = sess.run([outputs_L, states_L]\n",
    "                        , feed_dict={XL:inval, istate:istateval})\n",
    "    istateval = stateval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SAMPLED SETENCE> \n",
      " Perfection is achieved, not when there is nothing left to take away. when there is nothing left to take away. add, but when there is nothing more to add, but when there is nothing left to take away. awhere add, but\n",
      "\n",
      "<ORIGINAL SENTENCE> \n",
      " Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.\n"
     ]
    }
   ],
   "source": [
    "inval  = [[char_dic[prime[-1]]]]\n",
    "outval, stateval = sess.run([outputs_L, states_L]\n",
    "                    , feed_dict={XL:inval, istate:istateval})\n",
    "istateval = stateval\n",
    "index = np.argmax(outval)\n",
    "char  = char_set[index]\n",
    "chars = char\n",
    "for i in range(200):\n",
    "    inval = [[index]]\n",
    "    outval, stateval = sess.run([outputs_L, states_L]\n",
    "                        , feed_dict={XL:inval, istate:istateval})\n",
    "    istateval = stateval\n",
    "    # index = np.argmax(outval)\n",
    "    index = weighted_pick(softmax(outval))\n",
    "    char  = char_set[index]\n",
    "    chars += char\n",
    "print (\"<SAMPLED SETENCE> \\n %s\" % (prime+chars))\n",
    "print (\"\\n<ORIGINAL SENTENCE> \\n %s\" % (sentence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
